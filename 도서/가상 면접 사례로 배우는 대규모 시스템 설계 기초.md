> 기업 -> 시스템 설계 면접 광범휘하게 시행 => 이런 면접으로 의사소통 및 문제해결 능력이 소프트웨어 엔지니어가 업무상 필요로 하는 능력과 유사 모호한 문제를 어떻게 분석하고 단계적으로 해결하는지로 지원자를 **평가**

# 1장. 사용자 수에 따른 규모 확장성

---

## 단일 서버

- 사용자 -> 도메인 이름 이용하여 웹사이트 접속
- 사용자 접속 위해 도메인 이름 서비스(Domain Name service, DNS)에 질의하여 IP 주소로 변환 과정 필요
- IP 주소로 HTTP 요청 전달
- 요청 받은 웹 서버 HTML 페이지나 JSON 형태의 응답 반환

## 데이터베이스

> 사용자가 늘면서 여러 서버를 두게 된다.
> 한 서버는 웹/모바일 트래픽 처리 용도, 다른 하나는 데이터베이스 용

**비-관계형 데이터베이스가 적합한 경우**

- 아주 낮은 응답 지연시간이 요구
- 다루는 데이터가 비정형이라 관계형 데이터가 아닌 경우
- 데이터(JSON, YAML, XML 등)를 직렬화하거나 역직렬화 할 수 있기만 하면 되는 경우
- 아주 많은 양의 데이터를 저장할 필요가 있는 경우
  > 데이터 직렬화: 메모리를 디스크에 저장하거나 네트워크 통신에 사용 위한 형식으로 변환하는 것  
  > 데이터 역직렬화: 반대로 디스크에 저장한 데이터 읽거나, 네트워크 통신으로 받은 데이터를 메모리에 쓸 수 있도록 변환하는 것

## 수직적 규모 확장 vs 수평적 규모 확장

**수직적 규모 확장(scale up)**

- 서버에 고사양 자원을 추가하는 유입되는 트래픽의 양이 적을 때 적합

**단점**

- 한 대의 서버에 CPU나 메모리를 무한대로 증설할 방법 없음
  장애에 대한 자동복구 방안, 다중화 방안 제시하지 않음 -> 서버 장애 발생 시 웹/앱은 완전히 중단

**수평적 규모 확장(scale out)**

- 많은 서버를 추가하여 성능 개선하는 행위, 대규모 애플리케이션 지원하는 데에 적절

**로드밸런서**

- 부하 분산 집합에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할
  사용자는 로드밸런서의 공개 IP 주소로 접속 => 웹 서버는 클라이언트의 접속 직접 처리하지 않음

**데이터베이스 다중화**

> 다중화란
> 장애가 발생해도 예비 운용장비로 시스템의 기능을 계속할 수 있도록 하는 것을 말한다.

- 많은 데이터베이스 관리 시스템이 다중화를 지원
- 데이터베이스 서버 사이 주 서버, 부 서버 관계 설정 -> 데이터 원본은 주 서버에, 사본은 부 서버에 저장
- 쓰기 연산은 마스터 에서만 지원. 부 데이터베이스는 주 데이터베이스로부터 그 사본을 전달받고, 읽기 연산만을 지원.
- 데이터베이스를 변경하는 명령어들 ex) insert, delete, update 등은 마스터 DB로만 전달되어야 한다.
- 대부분 애플리케이션은 읽기 연산 비중 > 쓰기 연산 비중 => 부 DB가 주 DB 수 보다 많음

**다중화의 장점**

- 쓰기 연산은 주 DB로만, 읽기 연산은 부 DB로만 -> 분산 -> 병렬로 처리될 수 있는 질의 수 증가 -> 성능 증가
- 데이터를 지역적으로 떨어진 여러 장소에 다중화 시킴 -> DB 서버 중 일부가 파괴되어도 데이터가 보존될 수 있음
- 한 DB에 장애가 발생하더라도 다른 DB에 있는 데이터를 가져와 계속 서비스 진행 가능으로 가용성을 가짐

## 캐시

값 비싼 연산, 자주 참조되는 데이터를 메모리 안에 두고, 뒤이은 요청이 보다 빠르게 처리될 수 있도록 하는 저장소

> 애플리케이션의 성능은 DB를 얼마나 자주 호출하느냐에 크게 좌우

### 캐시계층

- 데이터가 잠시 보관되는 곳 DB 보다 빠름
- DB 부하를 줄일 수 있고 성능 또한 개선된다.
  **웹서버** <- 데이터가 캐시에 있으면 캐시에서 데이터 읽음 **캐시** <- 데이터가 캐시에 없으면 **DB**에서 데이터 읽어 캐시에 씀
  => 읽기 주도형 캐시 전략이라 부른다.

캐시할 데이터 종류, 크기, 액세스 패턴에 맞춰 다양한 캐시 전략이 있다.

캐시 서버를 이용하는 방법: 프로그래밍 언어로 API 제공

### 캐시 사용 시 유의할 점

- 캐시는 어떤 상황에 바람직한지 -> 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어나는 상황 시
- 어떤 데이터를 캐시에 두어야 하는지 -> 캐시는 데이터를 휘발성 메모리에 둠, 영속적으로 보관활 데이터를 캐시에 두는 것은 바람직하지 않다.
  캐시 서버 재시작되면 캐시 내의 모든 데이터 사라진다. 중요 데이터는 지속적 저장소에 두어야 한다.
- 캐시에 보관된 데이터는 어떻게 만료할 것인지 -> 만료된 데이터는 캐시에서 삭제되어야 함. 만료 정책이 없으면 데이터는 캐시에 계속 남게 되므로 적절한 만료 정책을 두어야 한다.
- 일관성은 어떻게 유지할지 -> 데이터 저장소의 원본 == 캐시 내의 사본 -> 일관성, 저장소 원본 갱신하는 연산과 캐시 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우 일관성은 깨질 수 있음
  (Scaling Memcache at Facebook 참조)
- 장애 대처는 어떻게 할지 -> 캐시 서버 한 대만 두는 경우 해당 서버는 단일 장애 지점이 될 가능성이 있다. SPOF를 피하기 위해 여러 지역에 걸쳐 캐시 서버 분산시켜야 한다.
  > 단일 장애 지점이란(Single Point of Failuer, SPOF)
  > 특정 지점에서의 장애가 전체 시스템의 동작을 중단시켜버릴 수 있는 경우
- 캐시 메모리의 크기 -> 캐시 메모리가 너무 작으면 액세스 패턴에 따라 데이터가 자주 캐시에서 밀려나버려 캐시 성능을 떨어뜨릴 수 있다. -> 캐시 메모리를 과 할당 한다. -> 캐시에 보관될 데이터가 갑자기 늘었을때 생길 문제도 방지할 수 있음
- 데이터 방출 정책
  - 널리 쓰이는 것은 LRU(Least Recently Used) -> 마지막으로 사용된 시점이 가장 오래된 데이터를 내보내는 정책
  - LFU(Least Frequently Used - 사용된 빈도가 가장 낮은 데이터 내보내는 정책)
  - FIFO(First In First Out - 가장 먼저 들어온 데이터를 가장 먼저 내보내는 정책)
    > 데이터 방출 정책: 캐시가 꽉 차버린 상황에 추가로 캐시에 데이터를 넣어야 하는 경우 기존 데이터를 내보내야 한다. 이때 어떤 기준으로 방출할 데이터를 정할 정책

## 콘텐츠 전송 네트워크(CDN)

> CDN: 정적 콘텐츠를 전송하는데 쓰이는, 지리적으로 분산된 서버의 네트워크 이미지, 비디오, CSS, Javascript 파일 등을 캐시할 수 있음  
> 정적 웹: 서버에서 콘텐츠를 가공해서 제공하는게 아닌 프로그래머가 작성한 콘텐츠를 그대로 제공하는 웹
> CDN 작동 방식

1. 사용자가 이미지 URL을 이용해 image.png에 접근 -> URL의 도메인은 CDN 서비스 사업자가 제공한 것
2. CDN 서버의 캐시에 해당 이미지가 없는 경우, 서버는 원본 서버에 요청하여 파일 가져옴, 원본 서버는 웹 서버일 수 있고, 아마존 S3 같은 온라인 저장소일 수 있음
3. 원본 서버가 파일 CDN 서버에 반환, 응답의 HTTP 헤더에는 해당 파일이 얼마나 오래 캐시될 수 있는지를 설명하는 TTL 값 들어있음
4. CDN 서버는 파일을 캐시하고 사용자 A에게 반환, 이미지는 TTL에 명시된 시간이 끝날 때까지 캐시
5. 다른 사용자가 같은 이미지에 대한 요청을 CDN 서버에 전송한다.
6. 만료되지 않은 이미지에 대한 요청은 캐시를 통해 처리.

### CDN 사용 시 고려해야 할 사항

- 비용: CDN은 보통 제3 사업자에 의해 운영됨, CDN으로 들어가고 나가는 데이터 전송 양에 따라 요금 지출, 자주 사용되지 않는 콘텐츠를 캐싱하는 것은 CDN 에서 빼는것을 고려
- 적절한 만료 시한 설정: 콘텐츠의 만료 시점이 너무 길면 콘텐츠 신선도는 떨어지고, 짧으면 원본 서버에 빈번히 접속하게 되므로 시의성이 중요힌 콘텐츠는 만료 시점을 잘 정해야 함
- CDN 장애에 대한 대처 방안: CDN 자체가 죽었을 경우 웹사이트/애플리케이션이 어떻게 동작해야 하는지 고려해야 함 일시적으로 CDN이 응답하지 않을 경우, 문제 감지하고 원본 서버로부터 콘텐츠 가져오도록 클라이언트 구성하는 것이 필요할 수 있음
- 콘텐츠 무효화 방법: 만료되지 않은 콘텐츠를 CDN에서 제거하는 방법
  - CDN 사업자가 제공하는 API 이용하여 콘텐츠 무효화
  - 콘텐츠의 다른 버전 서비스하도록 오브젝트 버저닝 이용
    > 콘텐츠의 새로운 버전 지정하는 방법
    > URL 마지막에 버전 번호 인자로 준다. ex) image.png?v=2

CDN 을 통해 정적 콘텐츠(JS, CSS, 이미지 등)는 웹 서버로 서비스 하지 않고 CDN 통해 제공 -> 더 나은 성능
캐시가 데이터베이스 부하를 줄여줌

## 무상태 웹 계층

> 무상태 웹 계층이란
> 상태 정보(사용자 세션 데이터 같은 것)를 웹 계층에서 제거하고 DB에 저장하여 필요할 때 가져오도록 하는 것

### 상태 정보 의존적인 아키텍처

- 사용자 마다 사용자의 상태정보를 갖고 있는 서버에만 http 요청을 보낼 수 있다.

### 무상태 아키텍처

- 모든 사용자가 같은 서버를 가리지 않고 http 요청하고 웹서버는 공유 저장소로 상태 정보를 접근하는 방식

### 데이터 센터

다중 데이터센터 아키텍처의 기술적 난제

- 트래픽 우회: 사용자에게서 가장 가까운 데이터 센터로 트래픽을 보내는 효과적인 방법 찾는 것
- 데이터 동기화: 데이터 센터마다 별도 DB를 보유하고 있는 경우 장애가 발생되어 트래픽 우회가 되어도 해당 데이터 센터에 데이터가 동기화 되 있는지 => 데이터 다중화
- 테스트와 배포: 자동화된 배포 도구가 모든 데이터 센터에 동일한 서비스를 설치하는지

### 메시지 큐

> 메시지 큐: 메시지 무손실(소비자가 메시지를 꺼낼 때까지 안전히 보관된다는 특성)을 보장하는, 비동기 통신 지원하는 컴포넌트 메시지의 버퍼 역할을 한다.

### 로그, 메트릭, 자동화

- 로그: 에러 로그 모니터링 서버 단위로 모니터링 가능하지만 로그를 단일 서비스로 모아주는 도구를 활용하면 편리하다
- 메트릭: 사업 현황에 관한 유용한 정보
  - 호스트 단위 메트릭: CPU, 메모리, 디스크 I/O 관한 메트릭
  - 종합 메트릭: 데이터베이스 계층의 성능, 캐시 계층의 성능 같은 것
  - 핵심 비즈니스 메트릭: 일별 능동 사용자, 수익, 재방문 같은 것
- 자동화: 개발, 빌드, 테스트, 배포 등을 자동화 해 생산성 향상 시키는 것

### 데이터베이스의 규모 확장

> DB의 수평적 확장은 샤딩이라고도 부른다.

> 샤딩: 대규모 데이터베이스를 샤드(shard)라고 부르는 작은 단위로 분할하는 기술

모든 샤드는 같은 스키마를 쓰지만 샤드에 보관되는 데이터 사이에는 중복이 없음
샤딩 전략을 구현할 때 고려해야 할 사항

- 샤딩 키(파티션 키): 데이터가 어떻게 분산될지 정하는 하나 이상의 칼럼
  데이터를 고르게 분할 할 수 있도록 샤딩 키를 정해야 한다.
  - 데이터의 재 샤딩: 데이터가 너무 많아져 하나의 샤드로 감당하기 어려울 때
  - 샤드 소진 현상이 발생할 때: 샤드 간 데이터 분포가 균등하지 못하여 어떤 샤드에 할당된 공간 소모가 다른 샤드보다 빨리 진행될 때 -> 샤드 키 계산하는 함수 변경하고 데이터 재배치 하여야 한다. 안정 해시 기법 활용
  - 유명인사 문제(핫스팟 키): 특정 샤드에 질의가 집중 되 서버 과부하 걸린 문제
  - 조인과 비정규화: DB 샤딩 -> 여러 샤드에 걸친 데이터 조인하기 힘들어짐 => 데이터베이스를 비정규화 하여 하나의 테이블에서 질의가 수행될 수 있도록 하는 것

### 시스템 규모 확장을 위한 기법

- 웹 계층은 무상태 계층으로
- 모든 계층에 다중화 도입
- 가능한 많은 데이터를 캐시하는 것
- 여러 데이터 센터 지원
- 정적 콘텐츠는 CDN 통해 서비스
- 데이터 계층은 샤딩을 통해 그 규모 확장할 것
- 각 계층은 독립적 서비스로 분할
- 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용

# 2장. 개략적인 규모 추정

> 보편적으로 통용되는 성능 수치상에서 사고 실험으로 추정치를 계산하는 행위 -> 어떤 설계가 요구사항에 부합할 것인지 보기 위한 것

규모 확장성을 표현하는 데 필요한 기본기 중요(2의 제곱수, 응답지연 값, 가용성에 관계된 수치들)

## 2의 제곱수

---

**응답지연 값**

- 메모리는 빠르고 디스크는 느리다.
- 디스크 탐색은 가능한 피하기
- 단순 압축 알고리즘은 빠르다.

## 가용성에 관계된 수치들

---

> 고가용성: 시스템이 오랜 시간 동안 지속적으로 중단 없이 운영될 수 있는 능력, 퍼센트로 표현한다.
> 100%는 시스템이 단 한번도 중단된 적 없음을 의미
> SLA(Service Level Agreement): 서비스 사업자가 보편적으로 사용하는 용어, 서비스 사업자와 고객 사이에 맺어진 합의를 의미

### QPS와 저장소 요구량 추정

**가정**

- 월간 능동 사용자는 3억명
- 50%의 사용자가 트위터를 매일 사용
- 평균적으로 각 사용자는 매일 2건의 트윗을 올린다.
- 미디어를 포함하는 트윗은 10% 정도
- 데이터는 5년간 보관
  **추정**
  QPS 추정치
- 일간 능동 사용자 = 3억\*50% = 1.5억명
- QPS=1.5억 \* 2트윗/24시간/3600초 = 약 3500
- 최대 QPS = 2 \* QPS = 약 7000

**미디어 저장 위한 저장소 요구량**

- 평균 트윗 크기
  - tweet_id에 64바이트
  - 텍스트에 140바이트
  - 미디어에 1MB
- 미디어 저장소 요구량: 1.5억 \* 2 \* 10% \* 1MB = 30TB/일
- 5년간 미디어 보관 위한 저장소 요구량: 30TB \* 365 \* 5 = 55PB

# 3장 시스템 설계 면접 공략법

## 효과적 면접을 위한 4단계 접근법

### 1. 문제 이해 및 설계 범위 확정

> 요구사항을 정확히 이해하는 데 필요한 질문하는 것이 중요

- 구체적으로 어떤 기능들을 만들어야 하는지
- 제품 사용자 수는 얼마나 되는지
- 회사의 규모는 얼마나 빨리 커지리라 예상하는지, 차후에 회사 규모는 얼머나 될거라 생각하는지
- 회사가 주로 사용하는 기술 스택은 무엇인지, 설계를 단순화하기 위해 활용할 수 있는 기존 서비스로는 어떤 것들이 있는지

### 2. 개략적인 설계안 제시 및 동의 구하기

- 설계안에 대한 최초 청사진을 제시하고 의견 구하기
- 화이트보드나 종이에 핵심 컴포넌트를 포함하는 다이어 그램 그리기(ex 클라이언트(모바일/웹), API, 웹 서버, 데이터 저장소, 캐시, CDN, 메시지 큐 등)
- 최초 설계안이 시스템 규모에 관계된 제약사항 만족하는지 개략적으로 계산

### 3. 상세설계

> 설계 대상 컴포넌트 사이의 우선순위 정하기

각 컴포넌트를 어떻게 설계할지 설명

### 4. 마무리

- 면접관에게 내가 만든 설계를 다시 한번 요약해주는 것도 도움이 된다.
- 오류가 발생하면 무슨 일이 생기는지(서버 오류, 네트워크 장애 등)
- 운영 이슈 -> 메트릭은 어떻게 수집하고 모니터링 할 것인지? 로그는? 시스템은 어떻게 배포할 것인지
- 미래에 닥칠 규모 확장 요구에는 어떻게 대처할 것인지

**면접에서 해야 할 것**

- 질문을 통해 확인하기, 스스로 내린 가정이 옳다고 생각하지 말아야 한다.
- 문제의 요구사항 이해하기
- 정답, 최선의 답안은 없다. 요구사항을 정확하게 이해했는지 다시 확인하기
- 면접관이 내 사고 흐름을 이해할 수 있도록 면접관과 소통하기
- 가능하다면 여러 해법을 함께 제시하기
- 개략적 설계에 면접관이 동의 했을 시, 각 컴포넌트의 세부사항을 설명하기(가장 중요한 컴포넌트 부터)
- 면접관의 아이디어를 이끌어 내기
- 포기하기 말기

**면접에서 하지 말아야 할 것**

- 전형적 면접 문제들에도 대비하지 않은 상태에선 면접장에 가지 말 것
- 요구사항이나 가정들을 분명히 하지 않은 상태에서 설계를 제세하지 말 것
- 초반부터 특정 컴포넌트의 세부사항을 깊이 설명하지 말 것(개략적 설계 후 세부사항으로 넘어갈 것)
- 진행 중에 막혔다면, 힌트를 청할 것
- 설계안을 내놓았다고 면접이 끝낫다고 생각하지 말고 의견을 일찍 자주 물어볼 것

# 4장. 처리율 제한 장치의 설계

> 처리율 제한 장치: 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치

ex

- 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
- 같은 IP 주소로는 하루에 10개 이상의 계정 생성할 수 없다.
- 같은 디바이스로는 주당 5회 이상 리워드를 요청할 수 없다.

**API에 처리율 제한 장치를 두면 좋은 점**

- DoS(Denial of Service) 공격에 의한 자원 고갈 방지 할 수 있다.
  (처리율 제한 장치는 추가 요청 처리를 중단함으로써 DoS 공격 방지)
- 비용 절감 -> 추가 요청 처리에 제한을 두면 서버를 많이 두지 않아도 되고, 우선순위가 높은 API에 더 많은 자원 할당 가능하다. 또는 제 3자 API에 사용료를 지불하고 있는 회사에게는 더욱 중요
- 서버 과부하를 막을 수 있다. -> 봇에서 오는 트래픽이나 사용자의 잘못된 이용 패턴으로 유발된 트래픽을 걸러낼 수 있다.

## 1. 문제 이해 및 설계 범위 확정

**요구사항**

- 설정된 처리율을 초과하는 요청은 정확하게 제한
- 낮은 응답시간: 처리율 제한 장치가 HTTP 응답시간에 악 영향을 주어선 안된다.
- 가능한 한 적은 메모리 사용
- 분산형 처리율 제한: 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야 함
- 예외처리: 요청이 제한되었을 때는 그 사실을 사용자에게 알려야 한다.
- 높은 결함 감내성: 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어선 안된다.

## 2. 개략적 설계안 제시 및 동의 구하기

**처리율 제한 장치는 어디에 둘 것인지**

> 직관적으론 장치는 클라이언트 측이나 서버 측에 둘 수 있다.

- 제한 장치를 클라이언트 측에 둔다면: 클라이언트는 처리율 제한을 안정적으로 걸 수 있는 장소로 적합하지 않다. 클라이언트 요청은 위변조가 쉽기 때문

- 제한 장치를 API 서버에 두는 방법
- 처리율 제한 미들웨어를 만들어서 해당 미들웨어로 API 서버로 가는 요청을 통제하는 것
  > 클라우드 마이크로서비스 의 경우 처리율 제한 장치는 보통 API 게이트웨이 라 불리는 컴포넌트에 구현됨
  > API 게이트웨이가 처리율 제한을 지원하는 미들웨어 이다.

**처리율 제한 장치를 어디에 두는 것의 지침**

- 프로그래밍 언어, 캐시 서비스 등 현재 사용하고 있는 기술 스택 점검, 현재 프로그래밍 언어가 서버 측 구현을 지원하기 충분할 정도로 효율이 높은지 확인
- 사업 필요에 맞는 처리율 제한 알고리즘 찾기
- 설계가 마이크로서비스 기반이고 사용자 인증이나 IP 허용목록 관리 등의 처리하기 위해 API 게이트웨이를 이미 설계에 포함시켰다면 -> 처리율 제한 기능 또한 게이트웨이에 포함시켜야 할 수 있다.
- 처리율 제한 서비스 만드는데 시간 소요됨 구현 인력 부족하다면 -> 상용 API 게이트웨이 쓰는것이 바람직

### 처리율 제한 알고리즘

#### 1. 토큰 버킷 알고리즘

**토큰 버킷 알고리즘의 동작 원리**

- 토큰 버킷은 지정된 용량 갖는 컨테이너로 버켓에는 사전 설정된 양의 토큰이 주기적으로 채워짐, 토큰이 꽉 찬 버킷에는 더 이상의 토큰은 추가되지 않음.
  토큰 공급기는 버킷에 매초 2개의 토큰 추가 버킷이 가득차면 추가 공급된 토큰은 버려짐
- 요청이 처리될 때마다 하나의 토큰 사용, 요청 도착 시 버킷에 충분한 토큰 있는지 검사
  - 충분한 토큰 있는 경우, 버킷에서 토큰 하나를 꺼내 요청을 시스템에 전달
  - 충분한 토큰 없는 경우, 해당 요청은 버려진다.

토큰 버킷 알고리즘의 인자

- 버킷 크기: 버킷에 담을 수 있는 토킨의 최대 개수
- 토큰 공급률: 초당 몇 개의 토큰이 버킷에 공급되는가

> 통상적으로 API 엔드포인트 마다 별도의 버킷을 둔다.
> ex) 사용자마다 한 번만 포스팅 할 수 있고 친구는 150명 까지 추가, 좋아요 버튼은 5번 까지 누를 수 있다면 사용자마다 3개의 버킷을 두어야 한다.

IP 주소별로 처리율 제한을 적용한다면 IP 주소마다 버킷 하나씩 할당해야 한다.
시스템의 처리율을 초당 10000개 요청으로 제한하고 싶다면, 모든 요청이 하나의 버킷을 공유하도록 해야 한다.
장점

- 구현 쉽다
- 메모리 사용 측면에서 효율적
- 짧은 시간에 집중되는 트래픽 처리 가능, 버킷에 토큰이 있기만 하면 요청은 시스템에 전달 됨

단점

- 버킷 크기, 토큰 공급률이라는 두 개의 인자를 적절하게 튜닝하는 것이 까다롭다

#### 2. 누출 버킷 알고리즘

> 토큰 버킷과 비슷하지만 요청 처리율이 고정되 있음
> 큐(FIFO)로 구현

**누출 버킷 동작원리**

- 요청 도착하면 큐가 가득 차 있는지 보고 빈자리가 있을 시 큐에 요청 추가
- 큐가 가득 차 있는 경우 새 요청은 버린다.
- 지정된 시간마다 큐에서 요청 꺼내 처리

누출 버킷 알고리즘의 인자

- 버킷 크기: 큐 사이즈와 같은 값
- 처리율: 지정된 시간당 몇 개의 항목 처리할지 지정하는 값(보통 초 단위)

장점

- 큐 크기 제한되 있어 메모리 사용량 측면에서 효율적
- 고정된 처리율 갖고 있기 때문에 안정적 출력 필요한 경우 적합

단점

- 단 시간에 많은 트래픽 몰리는 경우 큐에는 오래된 요청들이 쌓이고 요청들을 제때 처리 못하면 최신 요청들은 버려지게 된다.
- 두 개 인자 튜닝하기 까다롭다

#### 3. 고정 윈도 카운터 알고리즘

**고정 윈도 카운터 동작원리**

- 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙인다.
- 요청 접수될 때마다 카운터 값 1씩 증가
- 카운터 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려짐

장점

- 메모리 효율 좋다
- 이해하기 쉽다
- 윈도가 닫히는 시점에 카운터 초기화하는 방식은 특정 트래픽 패턴을 처리하기에 적합

단점

- 윈도 경계 부근에서 일시적으로 많은 트래픽 몰리는 경우, 기대했던 처리 한도보다 많은 양의 요청을 처리하게 됨

#### 4. 이동 윈도 로깅 알고리즘

**이동 윈도 동작원리**

- 요청의 타임스탬프 추적, 타임스탬프 데이터는 보통 레디스의 정렬 집합 같은 캐시에 보관
- 새 요청이 오면 만료된 타임스탬프 제거, 만료된 타임스탬프는 그 값이 현재 윈도의 시작 지점보다 오래된 타임스탬프를 말함
- 새 요청의 타임스탬프를 로그에 추가
- 로그 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달, 그렇지 않은 경우 처리 거부

장점

- 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않음

단점

- 다량의 메모리 사용, 거부된 요청의 타임스탬프를 보관하기 때문

#### 4. 이동 윈도 카운터 알고리즘

> 이동 윈도 카운터 = 고정 윈도 카운터 + 이동 윈도 로깅

**이동 윈도 카운터 동작원리**
처리율 제한 장치 한도가 분당 7개 요청으로 설정되 있고
이전 1분 동안 5개의 요청, 현재 1분 동안 3개의 요청이 있을 시
1분의 30% 시점에 도착한 새 요청의 경우  
현재 1분간의 요청 수 + 직전 1분간의 요청 수 \* 이동 윈도와 직전 1분이 겹치는 비율
=> 3 + 5 \* 70% = 6.5개
처리율 제한 한도가 분당 7개 요청이므로 현재 1분의 30% 시점에 도착한 요청은 시스템에 전달 된다.
장점

- 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태 계산하므로 짧은 시간에 몰리는 트래픽에 잘 대응
- 메모리 효율 좋다

단점

- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치 계산
